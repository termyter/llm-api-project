#!/usr/bin/env python3
"""
Ğ”ĞµĞ½ÑŒ 2: Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ±ĞµĞ· Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°
"""

import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url="https://api.deepseek.com"
)

# ĞĞ´Ğ¸Ğ½ Ğ¸ Ñ‚Ğ¾Ñ‚ Ğ¶Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ¾Ğ¸Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
QUESTION = "Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ?"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ—ĞĞŸĞ ĞĞ¡ 1: Ğ‘Ğ•Ğ— Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def request_without_limits():
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "user", "content": QUESTION}
        ]
    )
    return response

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ—ĞĞŸĞ ĞĞ¡ 2: Ğ¡ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ—ĞĞŸĞ ĞĞ¡ 3: ĞĞ¸Ğ·ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° (0.1) â€” Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹, Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·ÑƒĞµĞ¼Ñ‹Ğ¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def request_low_temperature():
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "user", "content": QUESTION}
        ],
        # ğŸ‘‰ ĞĞ¸Ğ·ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° = ÑÑ‚Ñ€Ğ¾Ğ³Ğ¸Ğ¹, Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·ÑƒĞµĞ¼Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
        temperature=0.1,
        max_tokens=150
    )
    return response

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ—ĞĞŸĞ ĞĞ¡ 4: Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° (1.5) â€” Ñ‚Ğ²Ğ¾Ñ€Ñ‡ĞµÑĞºĞ¸Ğ¹, Ğ½ĞµĞ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·ÑƒĞµĞ¼Ñ‹Ğ¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def request_high_temperature():
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "user", "content": QUESTION}
        ],
        # ğŸ‘‰ Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° = ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹, Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
        temperature=1.5,
        max_tokens=150
    )
    return response
def request_with_limits():
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {
                "role": "system",
                # ğŸ‘‰ Ğ¯Ğ²Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
                "content": (
                    "ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¼Ñƒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñƒ:\n"
                    "1. ĞĞ´Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â€” Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ.\n"
                    "2. ĞĞ´Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â€” Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¸Ğ· Ğ¶Ğ¸Ğ·Ğ½Ğ¸.\n"
                    "3. ĞĞ´Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â€” Ğ³Ğ´Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ.\n"
                    "ĞĞµ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸ Ğ·Ğ° Ñ€Ğ°Ğ¼ĞºĞ¸ ÑÑ‚Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹."
                )
            },
            {"role": "user", "content": QUESTION}
        ],
        # ğŸ‘‰ ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
        max_tokens=150,
        # ğŸ‘‰ Ğ£ÑĞ»Ğ¾Ğ²Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (stop sequence)
        stop=["4.", "\n\n\n"]
    )
    return response


def main():
    print("=" * 60)
    print(f"Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {QUESTION}")
    print("=" * 60)

    # --- Ğ‘Ğ•Ğ— Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹ ---
    print("\nğŸ“Œ Ğ—ĞĞŸĞ ĞĞ¡ 1: Ğ‘Ğ•Ğ— Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹")
    print("\nğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¸:")
    print(f"   user: {QUESTION}")
    print("\nğŸ“¥ ĞÑ‚Ğ²ĞµÑ‚Ğ¸Ğ»Ğ¸:")
    r1 = request_without_limits()
    answer1 = r1.choices[0].message.content
    print(answer1)
    print(f"\nğŸ“Š Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {r1.usage.total_tokens}")

    print("\n" + "-" * 60)

    # --- Ğ¡ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ ---
    print("\nğŸ“Œ Ğ—ĞĞŸĞ ĞĞ¡ 2: Ğ¡ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°")
    print("âš™ï¸  ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:")
    print("   â€¢ system prompt  â€” ÑĞ²Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ (3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)")
    print("   â€¢ max_tokens     â€” 150")
    print("   â€¢ stop sequence  â€” ['4.', '\\n\\n\\n']")
    print("\nğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¸:")
    print("   system: ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñƒ:")
    print("           1. ĞĞ´Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â€” Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ.")
    print("           2. ĞĞ´Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â€” Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ğ¸Ğ· Ğ¶Ğ¸Ğ·Ğ½Ğ¸.")
    print("           3. ĞĞ´Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â€” Ğ³Ğ´Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ.")
    print(f"   user:   {QUESTION}")
    print("\nğŸ“¥ ĞÑ‚Ğ²ĞµÑ‚Ğ¸Ğ»Ğ¸:")
    r2 = request_with_limits()
    answer2 = r2.choices[0].message.content
    print(answer2)
    print(f"\nğŸ“Š Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {r2.usage.total_tokens}")
    print(f"ğŸ›‘ ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸: {r2.choices[0].finish_reason}")

    print("\n" + "-" * 60)

    # --- ĞĞ¸Ğ·ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° ---
    print("\nğŸ“Œ Ğ—ĞĞŸĞ ĞĞ¡ 3: ĞĞ¸Ğ·ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°")
    print("âš™ï¸  ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:")
    print("   â€¢ temperature    â€” 0.1  (Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹, Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·ÑƒĞµĞ¼Ñ‹Ğ¹)")
    print("   â€¢ max_tokens     â€” 150")
    print("\nğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¸:")
    print(f"   user: {QUESTION}")
    print("\nğŸ“¥ ĞÑ‚Ğ²ĞµÑ‚Ğ¸Ğ»Ğ¸:")
    r3 = request_low_temperature()
    print(r3.choices[0].message.content)
    print(f"\nğŸ“Š Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {r3.usage.total_tokens}")

    print("\n" + "-" * 60)

    # --- Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° ---
    print("\nğŸ“Œ Ğ—ĞĞŸĞ ĞĞ¡ 4: Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°")
    print("âš™ï¸  ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:")
    print("   â€¢ temperature    â€” 1.5  (Ñ‚Ğ²Ğ¾Ñ€Ñ‡ĞµÑĞºĞ¸Ğ¹, Ğ½ĞµĞ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·ÑƒĞµĞ¼Ñ‹Ğ¹)")
    print("   â€¢ max_tokens     â€” 150")
    print("\nğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¸:")
    print(f"   user: {QUESTION}")
    print("\nğŸ“¥ ĞÑ‚Ğ²ĞµÑ‚Ğ¸Ğ»Ğ¸:")
    r4 = request_high_temperature()
    print(r4.choices[0].message.content)
    print(f"\nğŸ“Š Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {r4.usage.total_tokens}")

    print("\n" + "=" * 60)
    print("ğŸ“ˆ Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ• Ğ’Ğ¡Ğ•Ğ¥ Ğ—ĞĞŸĞ ĞĞ¡ĞĞ’:")
    print(f"  Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ 1 (Ğ±ĞµĞ· Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹)    â€” Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {r1.usage.total_tokens}")
    print(f"  Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ 2 (Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸)    â€” Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {r2.usage.total_tokens}")
    print(f"  Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ 3 (Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° 0.1)    â€” Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {r3.usage.total_tokens}")
    print(f"  Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ 4 (Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° 1.5)    â€” Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {r4.usage.total_tokens}")
    print("=" * 60)


if __name__ == "__main__":
    main()
